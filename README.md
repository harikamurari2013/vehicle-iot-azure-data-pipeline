# ğŸš— Vehicle IoT Data Pipeline â€” Azure End-to-End Data Engineering Project

![Azure](https://img.shields.io/badge/Azure-Data%20Factory-0078D4?style=flat&logo=microsoftazure)
![AWS](https://img.shields.io/badge/AWS-S3-FF9900?style=flat&logo=amazonaws)
![Azure Functions](https://img.shields.io/badge/Azure-Functions-0062AD?style=flat&logo=azurefunctions)
![SQL Server](https://img.shields.io/badge/Azure-SQL%20Server-CC2927?style=flat&logo=microsoftsqlserver)
![ADLS Gen2](https://img.shields.io/badge/Azure-ADLS%20Gen2-0078D4?style=flat&logo=microsoftazure)
![Status](https://img.shields.io/badge/Status-Completed-brightgreen)

---

## ğŸ“Œ Project Overview

An end-to-end **event-driven data pipeline** that ingests real-time vehicle IoT sensor data from **AWS S3** into **Azure SQL Server** â€” orchestrated via Azure Data Factory, validated using a serverless Azure Function, and secured with Azure Key Vault.

**500 vehicle records** successfully processed through the full pipeline end-to-end.

---

## ğŸ—ï¸ Architecture

```
IoT Sensors â†’ AWS S3 (year/month/date/file)
                    â†“
       ADF Pipeline 1 (S3 â†’ ADLS Gen2 Landing)
       [AWS Keys stored in Azure Key Vault]
                    â†“
         Azure Function â€” Blob Trigger
         (fires on every new file in landing/)
              â†™               â†˜
         staging/           rejected/
       (valid JSON)       (invalid JSON)
              â†“
       ADF Pipeline 2 (staging â†’ Azure SQL Server)
       [Storage Event Trigger â€” fully automated]
```

---

## ğŸ”§ Tech Stack

| Layer | Technology |
|---|---|
| IoT Source | AWS S3 |
| Secret Management | Azure Key Vault |
| Orchestration | Azure Data Factory |
| Storage | ADLS Gen2 (`landing`, `staging`, `rejected`) |
| Validation | Azure Functions (Node.js â€” Blob Trigger) |
| Serving Layer | Azure SQL Server |
| IaC | Terraform |
| CI/CD | GitHub Actions |

---

## ğŸ“ Repository Structure

```
vehicle-iot-azure-pipeline/
â”‚
â”œâ”€â”€ adf-pipelines/
â”‚   â”œâ”€â”€ pipeline1_s3_to_adls.json       # S3 â†’ ADLS Gen2 Landing
â”‚   â””â”€â”€ pipeline2_staging_to_sql.json   # Staging â†’ Azure SQL (Storage Event Trigger)
â”‚
â”œâ”€â”€ azure-functions/
â”‚   â””â”€â”€ BlobTriggerValidator/
â”‚       â”œâ”€â”€ index.js                    # Blob trigger â€” validates JSON, routes to staging/rejected
â”‚       â”œâ”€â”€ function.json               # Bindings: landing (in), staging/rejected (out)
â”‚       â””â”€â”€ package.json
â”‚
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ terraform/
â”‚       â”œâ”€â”€ main.tf                     # All Azure resources
â”‚       â””â”€â”€ variables.tf
â”‚
â”œâ”€â”€ sql-scripts/
â”‚   â””â”€â”€ create_tables.sql               # dbo.VehicleTelemetry DDL
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ Customer.json                   # 500 real vehicle records (actual data used)
â”‚   â””â”€â”€ sample_vehicle_payload.json     # 3-record sample
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ PROJECT_SUMMARY.md             # What was built, run, and the results
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ deploy.yml                  # CI/CD â€” test, plan, deploy
```

---

## âš¡ How the Pipeline Works

### Pipeline 1 â€” AWS S3 â†’ ADLS Gen2 Landing
ADF uses a Linked Service connected to AWS S3. AWS IAM access keys are stored in **Azure Key Vault** â€” never hardcoded. Files are copied from S3 into the ADLS Gen2 `landing` container.

### Azure Function â€” Blob Trigger Validator
Fires automatically the moment a file lands in `landing/`. Attempts to parse the content as JSON:
- **Valid** â†’ writes to `staging/`
- **Invalid** â†’ writes to `rejected/` (dead-letter)

### Pipeline 2 â€” Staging â†’ Azure SQL Server
A **Storage Event Trigger** fires automatically whenever the Azure Function writes a valid file to `staging/`. ADF copies the validated records into `dbo.VehicleTelemetry` in Azure SQL Server. No manual trigger needed.

---

## ğŸ” Security

AWS credentials are stored in Azure Key Vault and referenced by ADF Linked Services â€” zero hardcoded secrets anywhere in the pipeline.

---

## ğŸ“Š Sample Data Schema (Customer.json)

```json
{
  "VehicleID": "SK4523820602745727881887",
  "latitiude": 86.8332365824,
  "longitude": -78.5162003456,
  "City": "MÃ©rignac",
  "temeprature": 82,
  "speed": 191
}
```

500 records processed. See [`notebooks/Customer.json`](vehicle-iot-azure-pipeline/notebooks/Customer.json) for the full dataset.

---

## ğŸ“„ Project Summary

Full details of resources provisioned, pipeline configuration, and results:
ğŸ‘‰ [`docs/PROJECT_SUMMARY.md`](vehicle-iot-azure-pipeline/docs/PROJECT_SUMMARY.md)
